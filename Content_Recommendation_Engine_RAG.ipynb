{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oEoA0P0drP_I8bojwR-4JmjdlNOSRmUY",
      "authorship_tag": "ABX9TyNjQY/J0sEi+7MNmj+a57oD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Nettoyer les Donn√©es"
      ],
      "metadata": {
        "id": "pOM_6JBCDEYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation des d√©pendances, t√©l√©chargement du mod√®le spaCy et ex√©cution du script de nettoyage des donn√©es"
      ],
      "metadata": {
        "id": "6IFiqfcB-7IT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "epdmhObwAdsF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751727073758,
          "user_tz": -60,
          "elapsed": 20190,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "82125811-1066-44e7-972b-9cd669306e56"
      },
      "outputs": [],
      "source": [
        "# Installer les d√©pendances\n",
        "!pip install pandas spacy fr_core_news_sm  # ou en_core_web_sm\n",
        "\n",
        "# T√©l√©charger le mod√®le spaCy\n",
        "!python -m spacy download fr_core_news_sm\n",
        "\n",
        "# Lancer le script\n",
        "!python clean_data.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9vO7t3ESEnst",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751727172684,
          "user_tz": -60,
          "elapsed": 8961,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "d494356d-3a9e-4038-ccf1-2a1b91665ba5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas spacy langdetect tqdm\n",
        "!python -m spacy download fr_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YLbLv3XkHfrq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751727888799,
          "user_tz": -60,
          "elapsed": 14677,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "128a409e-42eb-4a0b-f42a-c44af10ad827"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation des d√©pendances, t√©l√©chargement du mod√®le spaCy et ex√©cution du script de nettoyage des donn√©es"
      ],
      "metadata": {
        "id": "_0Tbn8H3_d9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clean_data.py\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "from typing import List, Dict\n",
        "from unicodedata import normalize\n",
        "from langdetect import detect\n",
        "import warnings\n",
        "from tqdm import tqdm  # Pour une barre de progression\n",
        "\n",
        "# Configuration initiale\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "tqdm.pandas()  # Active la barre de progression pour pandas\n",
        "\n",
        "# Initialiser spaCy avec une limite √©tendue\n",
        "try:\n",
        "    nlp = spacy.load(\"fr_core_news_sm\")\n",
        "    nlp.max_length = 2000000  # Double la limite de caract√®res\n",
        "except OSError:\n",
        "    print(\"‚ö†Ô∏è Mod√®le spaCy non trouv√©. Veuillez l'installer avec :\")\n",
        "    print(\"python -m spacy download fr_core_news_sm\")\n",
        "    exit(1)\n",
        "\n",
        "def is_chinese(text: str) -> bool:\n",
        "    \"\"\"D√©tecte si le texte est en chinois\"\"\"\n",
        "    try:\n",
        "        if not isinstance(text, str) or len(text.strip()) < 10:\n",
        "            return False\n",
        "        # On v√©rifie seulement les premiers 1000 caract√®res pour la d√©tection de langue\n",
        "        return detect(text[:1000]) == 'zh'\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Nettoie et normalise le texte avec gestion des longs textes\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str) or is_chinese(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Limite la taille du texte pour spaCy (500k caract√®res max)\n",
        "    processing_text = text[:500000]\n",
        "\n",
        "    # Normalisation Unicode\n",
        "    processing_text = normalize(\"NFKD\", processing_text).encode(\"ASCII\", \"ignore\").decode(\"utf-8\")\n",
        "\n",
        "    # Nettoyage de base\n",
        "    processing_text = re.sub(r\"http\\S+|@\\w+|#\\w+\", \"\", processing_text)\n",
        "    processing_text = re.sub(r\"[^a-zA-Z0-9\\s√©√®√™√´√†√¢√§√Æ√Ø√¥√∂√π√ª√º√ß]\", \" \", processing_text)\n",
        "\n",
        "    # Traitement par morceaux si le texte est trop long\n",
        "    chunk_size = 100000\n",
        "    text_chunks = [processing_text[i:i+chunk_size]\n",
        "                  for i in range(0, len(processing_text), chunk_size)]\n",
        "\n",
        "    final_tokens = []\n",
        "    for chunk in text_chunks:\n",
        "        doc = nlp(chunk.lower())\n",
        "        final_tokens.extend([token.lemma_ for token in doc\n",
        "                           if not token.is_stop and not token.is_punct])\n",
        "\n",
        "    return \" \".join(final_tokens).strip()\n",
        "\n",
        "def preprocess_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Applique le pr√©traitement de mani√®re optimis√©e\"\"\"\n",
        "    # 1. Nettoyage initial\n",
        "    df = df.drop_duplicates(subset=[\"URL\"])\n",
        "    df = df.dropna(subset=[\"Contenu\", \"Titre\"])\n",
        "    print(f\"üìä Apr√®s nettoyage initial : {len(df)} articles\")\n",
        "\n",
        "    # 2. Filtrage des articles en chinois\n",
        "    print(\"üîç Filtrage des articles en chinois...\")\n",
        "    df['is_chinese'] = df['Contenu'].progress_apply(is_chinese)\n",
        "    chinese_count = df['is_chinese'].sum()\n",
        "    print(f\"üöÆ {chinese_count} articles en chinois d√©tect√©s et supprim√©s\")\n",
        "    df = df[~df['is_chinese']].copy()\n",
        "\n",
        "    # 3. Normalisation du texte avec barre de progression\n",
        "    text_columns = [\"Titre\", \"Auteur\", \"Description\", \"Contenu\"]\n",
        "    for col in text_columns:\n",
        "        if col in df.columns:\n",
        "            print(f\"üîÑ Normalisation de la colonne {col}...\")\n",
        "            df[col] = df[col].progress_apply(normalize_text)\n",
        "\n",
        "    # 4. Formatage des dates\n",
        "    if \"Date\" in df.columns:\n",
        "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # 5. Ajout d'ID\n",
        "    df[\"ID\"] = range(1, len(df) + 1)\n",
        "\n",
        "    return df[[\"ID\", \"Titre\", \"Auteur\", \"Date\", \"Source\", \"URL\", \"Contenu\"]]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        print(\"üìÇ Chargement des donn√©es...\")\n",
        "        df = pd.read_csv(\"/content/drive/MyDrive/merged_articles.csv\")\n",
        "        print(f\"üîç Donn√©es brutes charg√©es : {len(df)} articles\")\n",
        "\n",
        "        cleaned_df = preprocess_dataframe(df)\n",
        "\n",
        "        print(\"üíæ Sauvegarde des donn√©es nettoy√©es...\")\n",
        "        cleaned_df.to_csv(\"/content/drive/MyDrive/cleaned_articles.csv\", index=False)\n",
        "        print(f\"‚úÖ {len(cleaned_df)} articles sauvegard√©s\")\n",
        "        print(\"üìä Aper√ßu final :\")\n",
        "        print(cleaned_df.head(3).to_markdown(tablefmt=\"grid\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur : {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwvG4dZjE3l0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751728462346,
          "user_tz": -60,
          "elapsed": 539947,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "6dfba4b9-fcfd-44d3-e320-2cf35d0945dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construction du Syst√®me RAG"
      ],
      "metadata": {
        "id": "qKcyhZGkQjd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation des packages essentiels pour traitement de donn√©es et indexation vectorielle (FAISS CPU et GPU optionnel)"
      ],
      "metadata": {
        "id": "52Zkyyjo_qxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers faiss-cpu numpy pandas tqdm\n",
        "# Pour GPU NVIDIA (optionnel) :\n",
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YdfsI6wKQiSU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751730423594,
          "user_tz": -60,
          "elapsed": 141479,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "db6e5231-36e3-492d-ba0e-38c928b00134"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/cleaned_articles.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "71YG9w5sR83U",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751730622980,
          "user_tz": -60,
          "elapsed": 293,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "53732a75-ed8e-427f-dceb-e5b924db0985"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woZUXEp0Slh5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751730773953,
          "user_tz": -60,
          "elapsed": 12,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "e4dfdf93-78fe-4157-e709-fff867c4d98a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syst√®me RAG complet : g√©n√©ration d‚Äôembeddings, indexation FAISS, recherche s√©mantique interactive et sauvegarde dans Google Drive"
      ],
      "metadata": {
        "id": "e5Gouv-q_xD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rag_system.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Configuration des chemins Google Drive\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/rag_project\"\n",
        "os.makedirs(DRIVE_PATH, exist_ok=True)\n",
        "\n",
        "# 1. Charger les donn√©es nettoy√©es\n",
        "INPUT_PATH = \"/content/drive/MyDrive/cleaned_articles.csv\"\n",
        "print(f\"üìÇ Chargement des donn√©es depuis {INPUT_PATH}...\")\n",
        "df = pd.read_csv(INPUT_PATH)\n",
        "\n",
        "# V√©rification des colonnes disponibles\n",
        "print(\"üìä Colonnes disponibles:\", df.columns.tolist())\n",
        "\n",
        "# Utilisation des colonnes existantes\n",
        "texts = df[\"Contenu\"].fillna(\"\").tolist()\n",
        "metadata_columns = [\"ID\", \"Titre\", \"URL\"]  # Colonnes obligatoires\n",
        "metadata = df[metadata_columns].to_dict('records')\n",
        "\n",
        "# 2. G√©n√©ration des embeddings\n",
        "EMBEDDINGS_PATH = f\"{DRIVE_PATH}/article_embeddings.npy\"\n",
        "print(\"üîß Cr√©ation des embeddings...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# G√©n√©ration par batch pour les grands datasets\n",
        "embeddings = []\n",
        "batch_size = 32 if len(texts) > 1000 else 64\n",
        "\n",
        "for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding des articles\"):\n",
        "    batch = texts[i:i + batch_size]\n",
        "    embeddings.append(model.encode(batch, show_progress_bar=False))\n",
        "\n",
        "embeddings = np.vstack(embeddings)\n",
        "np.save(EMBEDDINGS_PATH, embeddings)\n",
        "print(f\"üíæ Embeddings sauvegard√©s dans {EMBEDDINGS_PATH}\")\n",
        "\n",
        "# 3. Cr√©ation de l'index FAISS\n",
        "INDEX_PATH = f\"{DRIVE_PATH}/faiss_index.index\"\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "index.add(embeddings)\n",
        "faiss.write_index(index, INDEX_PATH)\n",
        "print(f\"üèóÔ∏è Index FAISS sauvegard√© dans {INDEX_PATH}\")\n",
        "\n",
        "# 4. Fonction de recherche am√©lior√©e\n",
        "def search(query: str, top_k: int = 5, min_similarity: float = 0.5):\n",
        "    \"\"\"Recherche les articles les plus pertinents\"\"\"\n",
        "    try:\n",
        "        query_embedding = model.encode([query])\n",
        "        distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "        results = []\n",
        "        for idx, score in zip(indices[0], distances[0]):\n",
        "            if idx >= 0 and score >= min_similarity:\n",
        "                result = metadata[idx].copy()\n",
        "                result[\"score\"] = float(score)\n",
        "\n",
        "                # Ajout d'un extrait du contenu (premi√®res 100 caract√®res)\n",
        "                result[\"extrait\"] = texts[idx][:100] + \"...\" if len(texts[idx]) > 100 else texts[idx]\n",
        "                results.append(result)\n",
        "\n",
        "        return sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur lors de la recherche: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# 5. Test du syst√®me\n",
        "print(\"\\nüß™ Phase de test - Tapez 'exit' pour quitter\")\n",
        "while True:\n",
        "    query = input(\"\\nüîé Entrez votre requ√™te: \")\n",
        "    if query.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    results = search(query)\n",
        "\n",
        "    if not results:\n",
        "        print(\"Aucun r√©sultat trouv√©. Essayez avec d'autres termes.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nüìö Meilleurs r√©sultats pour '{query}':\")\n",
        "    for i, res in enumerate(results, 1):\n",
        "        print(f\"\\n{i}. {res['Titre']} (score: {res['score']:.2f})\")\n",
        "        print(f\"   üìù Extrait: {res['extrait']}\")\n",
        "        print(f\"   üîó Lien: {res['URL']}\")\n",
        "\n",
        "print(\"\\n‚úÖ Syst√®me RAG pr√™t! Tous les fichiers sont sauvegard√©s dans Google Drive:\")\n",
        "print(f\"- Index FAISS: {INDEX_PATH}\")\n",
        "print(f\"- Embeddings: {EMBEDDINGS_PATH}\")\n",
        "print(f\"- Donn√©es originales: {INPUT_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629,
          "referenced_widgets": [
            "b3b38e6bf3f247818db40cc83f8c0c03",
            "7d7d03c536814ef99baddd5cd0702721",
            "89f2501187dc46b88bf6a776b16a009f",
            "201e8290b6f04e2b869b4353b479801b",
            "522cf5852c334c6e9ef72ab5baea1a02",
            "66d2423ed6db4a34974b17d516e7a6f6",
            "80203dd97c9d4fbf89f605d67d33e04b",
            "3ae2ec895ba942708a9a18c8e0026335",
            "c72187a23f2a4d16a5cf00aba82c3db1",
            "077e44e7b0474347bd0ebd35e6c0de24",
            "0dd33393531d455eb31387cf7fc29c2e",
            "052fe633bdee497a87282863d2d1da5c",
            "c818050e25a446969e8d6f1771e2aa03",
            "8aca18bed3b94c569de5e130fe45066c",
            "eca6ca9e374d4343ae9e96f5dad97ad3",
            "74c5cd7e98644267b74d43be8ff3131b",
            "7981f0fd1167423f88a0bc7db927640a",
            "0e98dcb58dfd4b2699658a4e26042161",
            "77bb938303134a1fa854fa9ac3a4456f",
            "4d75d0b9ca2e4b76aad35adb01222dfc",
            "244b6ee9254942b481ae3311f59117e9",
            "86f4e37a119547c79e8806270f85be68",
            "5726a60094fb47cbafb7b403651b5bc4",
            "94259b191ddf488fba9afef3a1513ea6",
            "9fc892a50a094a1ab48c7dd233582d9d",
            "467eece76a6d4521b34bb0cb60c5cb7d",
            "6bb57e2f0e3646a38e5fe46fdbe3263b",
            "a8053da8fe1548a9af2fa19f6a3c5c2c",
            "285603acc4124e78a711a4e2046e2828",
            "8e6cb4679b7f460a89ea673f3f9aea70",
            "47e056b41afe4a55968956039317150e",
            "3a836a90a49142fb8f6e1d748b694803",
            "1fea0225d9ea457cbe3d1741e2863f86",
            "f6aec1c9d72e4e518b24995c4f5dee9e",
            "db63283c58b4413693160962f5443abb",
            "4984239a8f0a469388de4fdfcb9714d7",
            "595d663010044a598fb42faa4292b357",
            "2a2ecdbc7fc747ff9bdea3da5dd301b5",
            "0ef7768f9d7a455aa610c4b9a56c8ce4",
            "9b1549c24c394a008e25f02ce6f51d47",
            "44db647452f5404fb6ea0a614bf33faf",
            "ae414827d2e949debc4246ce28877f94",
            "c92618d1d5ec4da7aa5d494ba166b5e7",
            "02843696d8a7464288778dab6e2fa485",
            "f5bc47910ee149b3bd60a866fbda8fcb",
            "63fee3341edc4b53835156d396ef7013",
            "f7f5e6980b6848169bf241414bfdfb35",
            "c5c36715db6e41f9931c666f7fdfca56",
            "b6277faa338f4fc58d73c63f6f638b5a",
            "24e9aab893f746e5bfae37e098a3438f",
            "993556f073154fc19f8d10f318bdaa0a",
            "2c4248c3391542e1acb47fb925f2d999",
            "4f3c45d04c574975aa327bcd5236e107",
            "6af019e1d2ab4edbbec34cbcf70207a2",
            "35981c43193f4507862c1e9681b11a2e",
            "82bd368fa7684fd28db3c2de76707fb6",
            "f78fdad8524042219417d44861880117",
            "e02d20f50f92474f9089a945a21cccef",
            "359aab745c864fdfaeccf1f273cb14e3",
            "7d5398edfde145c9bac2f22a8e8fba47",
            "fba8461624d640b1a18352b37dc1629f",
            "fa7bb1d599384ad79bf4a185c1c65e14",
            "1c7a827b9e05411dac761186c7d22be9",
            "b2a181359b6d4498a4b7313f9b968b55",
            "b31c60c8fa604d55a96fe524be443847",
            "519a768366784d4296aacec1788aab4f",
            "1427771a55c24418aed951408fd88dce",
            "c9ad3df7f9de44818ce31378cc4bf44c",
            "56353a6486f44aab8a5897a8883f4e18",
            "2faecdc9695141a5be924b096673d74c",
            "7fbb0c9e550547088a9d746ad3eee38c",
            "75871673b7744a5d99aba597bc95d2b3",
            "ebec1d300a7e4000934bfa382006c5e1",
            "cb8bc54470fe4fa1b5ab8ca53ad9baee",
            "e536faf8b6ed4de9b1c5b6a3a36a46a8",
            "1bc366b8539a4666b9c0f38592ccc886",
            "13cf631871864e298a2da27cf3032bc1",
            "3787da8ef71642bb8499ff3796f6d58d",
            "95ad618a53534f3ab25932011caadeee",
            "6cfceac5a9b748c282dad0e619af9ee3",
            "a0101abe9df54549bb2f2b685c510c64",
            "8717d2aa6b7b4d86b5439372ca0b8957",
            "64db959ab7e64c67ad545953b6224880",
            "013f1143374e467b9df1eb7476b90044",
            "2429cf5cff4747e38540ce9521d7165e",
            "fcc43462591c41c7ab927f640a6ace39",
            "f2775819b7eb43749467b44a2f088feb",
            "6f22404b207f4b1d973df3343cdf76cb",
            "b23d10124b4b4db39e8205cca8b084a6",
            "fe354fcb604043bba53f6c735b2c7b43",
            "59ca9fa475044a8d88247a169eaa9c53",
            "99571dfb1dd1420e8116d0e52bd28c3e",
            "b60f3506ec874e42a8afc061f24588ee",
            "25d41384cc194c73a2ff70feb426ebab",
            "256eb8f47af34149af4bdae806cd455e",
            "8e7bfac3f2564f3aa407581641035991",
            "cd792fdb0aea41cf9061349b38bf3b2a",
            "255d1de72dc74dfd960148793d8980b7",
            "b2be59d4cc2b4c8b8198f0515a289527",
            "08118680174744c3baff67668dc1a1a1",
            "0274fe2a6ddc4aeea7c396b5353dc3de",
            "1bd77d06a0d44bf3b7b57e73a5a994e7",
            "d2cb5fee433b4f7d9abb867f29b0148b",
            "58616fca65f746139062dd32db0e8a98",
            "30331031e14b4363b37a6b2f0d577c47",
            "4c2efb899a5045c99f2e01b8f4c63914",
            "94ca71d77dd244d492794ace5f5cfa33",
            "4bbe9485d00d4dcbbaa8bddb824f7e8e",
            "5f222a556a6e4458a44e79337b96b483",
            "fe793590d5704b44bdd504c1e4ea7bed",
            "6cb2ada98f2b40a18709cc239fbdc965",
            "7a908c8ceb8044dca760adf8a7b7d005",
            "1ab854da6ae34de58dedd940f1c45df3",
            "219ea26e266a4471865fa7cfd595a0a4",
            "986868e2dae04afb9c4a6232cd2899cd",
            "2bc9245f181546c9a8d52fd374f55e15",
            "f43e1e3ddc094ce6851890ec32212110",
            "e11ca9c1a16e47fca0957320208d202d",
            "e2fe76a4706743239ad8c2d47a83870d",
            "c440ae965dfd4e0a9fffc2ae03c4b582",
            "b6ffc5153c074e8f9f10120be29f93b2"
          ]
        },
        "id": "hxKapnkiQwcD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751731319466,
          "user_tz": -60,
          "elapsed": 425626,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "98ecbcd1-b365-4b11-d7ce-253c64371af1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script de test du syst√®me RAG : chargement de l‚Äôindex FAISS, recherche s√©mantique et affichage interactif des r√©sultats"
      ],
      "metadata": {
        "id": "01ZzxrU0_2ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rag_test.py\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "\n",
        "# Chemins vers les fichiers sauvegard√©s\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/rag_project\"\n",
        "INDEX_PATH = f\"{DRIVE_PATH}/faiss_index.index\"\n",
        "EMBEDDINGS_PATH = f\"{DRIVE_PATH}/article_embeddings.npy\"\n",
        "DATA_PATH = \"/content/drive/MyDrive/cleaned_articles.csv\"\n",
        "\n",
        "# Charger les ressources existantes\n",
        "print(\"‚öôÔ∏è Chargement des ressources...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "index = faiss.read_index(INDEX_PATH)\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "texts = df[\"Contenu\"].fillna(\"\").tolist()\n",
        "metadata = df[[\"ID\", \"Titre\", \"URL\"]].to_dict('records')\n",
        "\n",
        "def search(query: str, top_k: int = 3):\n",
        "    \"\"\"Fonction de recherche optimis√©e\"\"\"\n",
        "    query_embedding = model.encode([query])\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    results = []\n",
        "    for idx, score in zip(indices[0], distances[0]):\n",
        "        if idx >= 0:\n",
        "            result = metadata[idx].copy()\n",
        "            result[\"score\"] = float(score)\n",
        "            result[\"extrait\"] = texts[idx][:150] + \"...\" if len(texts[idx]) > 150 else texts[idx]\n",
        "            results.append(result)\n",
        "\n",
        "    return sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
        "\n",
        "# Interface de test\n",
        "print(\"\\nüîç Testez votre syst√®me RAG (tapez 'exit' pour quitter)\")\n",
        "while True:\n",
        "    query = input(\"\\nEntrez votre requ√™te : \")\n",
        "    if query.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    results = search(query)\n",
        "\n",
        "    if not results:\n",
        "        print(\"Aucun r√©sultat trouv√©.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nüîé {len(results)} r√©sultats pour '{query}':\")\n",
        "    for i, res in enumerate(results, 1):\n",
        "        print(f\"\\n{i}. [{res['score']:.2f}] {res['Titre']}\")\n",
        "        print(f\"   {res['extrait']}\")\n",
        "        print(f\"   {res['URL']}\")\n",
        "\n",
        "print(\"\\n‚úÖ Test termin√©\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KtJDDVHVrfK",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751731739444,
          "user_tz": -60,
          "elapsed": 38850,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "ed33c0e0-3c04-4868-e820-f3693d113c19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FiS80H3-WvzJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751731884521,
          "user_tz": -60,
          "elapsed": 10195,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "1ac7efe9-4e9e-42f0-b57e-ac527ae11f6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community openai langchain-huggingface faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eCk19WafYIZW",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751732237048,
          "user_tz": -60,
          "elapsed": 7167,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "6eb19dde-4589-4e9e-dcdd-768710f3ee58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZEMDhQtxZRij",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751732577192,
          "user_tz": -60,
          "elapsed": 47344,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "7adcc74e-1b57-4046-f10b-cefe0390df63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Fichiers dans rag_project:\", os.listdir(\"/content/drive/MyDrive/rag_project\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yr3aHKmaFBR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751732738111,
          "user_tz": -60,
          "elapsed": 20,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "faf0eb66-9d1b-43ac-f785-51268096e833"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D√©marrage asynchrone du serveur Ollama via un thread s√©par√©"
      ],
      "metadata": {
        "id": "pylXguGS_9_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "\n",
        "def run_ollama():\n",
        "    subprocess.run([\"ollama\", \"serve\"], check=True)\n",
        "\n",
        "# D√©marrer dans un thread s√©par√©\n",
        "threading.Thread(target=run_ollama, daemon=True).start()"
      ],
      "metadata": {
        "id": "vE0qEIhsgOnW",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751734350452,
          "user_tz": -60,
          "elapsed": 5,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl http://localhost:11434\n",
        "# Doit retourner \"Ollama is running\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8tP9V8ggPjT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751734360372,
          "user_tz": -60,
          "elapsed": 209,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "c64e3dc9-dab0-4395-cc8b-02f852927714"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull mistral"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY-ZkbSUgTSi",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751734446730,
          "user_tz": -60,
          "elapsed": 77361,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "2e4b9a22-9ed3-48a8-beb4-ee10dda41338"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatbot interactif pour recherche d‚Äôarticles avec embeddings SentenceTransformer et index FAISS"
      ],
      "metadata": {
        "id": "j3CxkBfjADhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Charger les ressources\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/rag_project\"\n",
        "INDEX_PATH = f\"{DRIVE_PATH}/faiss_index.index\"\n",
        "DATA_PATH = \"/content/drive/MyDrive/cleaned_articles.csv\"\n",
        "\n",
        "print(\"‚öôÔ∏è Chargement des ressources...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "index = faiss.read_index(INDEX_PATH)\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "texts = df[\"Contenu\"].fillna(\"\").tolist()\n",
        "metadata = df[[\"ID\", \"Titre\", \"URL\"]].to_dict('records')\n",
        "\n",
        "def search_articles(query: str, top_k: int = 5):\n",
        "    \"\"\"Recherche les articles les plus pertinents\"\"\"\n",
        "    query_embedding = model.encode([query])\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    results = []\n",
        "    for idx, score in zip(indices[0], distances[0]):\n",
        "        if idx >= 0:\n",
        "            result = metadata[idx].copy()\n",
        "            result[\"score\"] = float(score)\n",
        "            result[\"extrait\"] = texts[idx][:200] + \"...\" if len(texts[idx]) > 200 else texts[idx]\n",
        "            results.append(result)\n",
        "    return sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
        "\n",
        "def main():\n",
        "    print(\"\\n=== CHATBOT D'ARTICLES ===\")\n",
        "    while True:\n",
        "        question = input(\"\\nPose ta question (ou 'exit'): \").strip()\n",
        "        if question.lower() == 'exit':\n",
        "            break\n",
        "        articles = search_articles(question, top_k=5)\n",
        "        if not articles:\n",
        "            print(\"Aucun article trouv√©.\")\n",
        "            continue\n",
        "        print(f\"\\n{len(articles)} articles trouv√©s pour ta question :\\n\")\n",
        "        for i, art in enumerate(articles, 1):\n",
        "            print(f\"{i}. {art['Titre']}\")\n",
        "            print(f\"   üîó Lien : {art['URL']}\")\n",
        "            print(f\"   üìù R√©sum√© : {art['extrait']}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdxKmyAGVrzk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751741674553,
          "user_tz": -60,
          "elapsed": 834266,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "9a418260-efc1-4f9d-cc37-8595fee839a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/merged_articles.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4HoqmVMP8MOt",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1751742840532,
          "user_tz": -60,
          "elapsed": 19,
          "user": {
            "displayName": "fatimazohra jell",
            "userId": "14548648197489226722"
          }
        },
        "outputId": "f499b7bf-1fdd-437f-9e4e-162287c60f43"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}